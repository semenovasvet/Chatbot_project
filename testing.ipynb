{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.chrome.service import Service as ChromeService \n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    " \n",
    "# instantiate options \n",
    "options = webdriver.ChromeOptions() \n",
    " \n",
    "# run browser in headless mode \n",
    "options.headless = True \n",
    " \n",
    "# instantiate driver \n",
    "driver = webdriver.Chrome(service=ChromeService( \n",
    "\tChromeDriverManager().install()), options=options) \n",
    " \n",
    "# load website \n",
    "url = 'https://altruan.de/produkt/meditrade-nitril-nextgen-puderfreie-einmalhandschuh/' \n",
    "# url = 'https://angular.io/' \n",
    " \n",
    "# get the entire website content \n",
    "driver.get(url) \n",
    "pageInfo = driver.page_source\n",
    "f = open(\"htmlInfo.html\", \"w\", encoding=\"utf-8\")\n",
    "f.write(pageInfo)\n",
    "f.close()\n",
    "# select elements by class name \n",
    "# elements = driver.find_elements(By.NAME, 'text-container')\n",
    "# for title in elements: \n",
    "# \tprint(title)\n",
    "\t# select H2s, within element, by tag name \n",
    "\t# heading = title.find_element(By.TAG_NAME, 'h2').text \n",
    "\t# # print H2s \n",
    "\t# print(heading)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Создаю csv таблицу из шопифая\"\"\"\n",
    "\n",
    "endpoint = \"products.json\"\n",
    "url = f\"https://d4cb5c.myshopify.com/admin/api/2023-10/{endpoint}\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-Shopify-Access-Token\": \"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\"\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(columns=[\"title\", \"body\", \"type\"])\n",
    "\n",
    "response = requests.get(url=url, headers=headers)\n",
    "a = json.loads(response.text)\n",
    "\n",
    "for item in a[\"products\"]:\n",
    "    title = item[\"title\"]\n",
    "    body = item[\"body_html\"]\n",
    "    itemType = item[\"product_type\"]\n",
    "    new_row = {\"title\": title, \"body\": body, \"type\": itemType}\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "df.to_csv(\"productData.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OPENAI_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adski\\OneDrive\\Документы\\Project\\testing.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m load_dotenv()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m https://api.openai.com/v1/chat/completions\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49menviron[\u001b[39m\"\u001b[39;49m\u001b[39mOPENAI_API_KEY\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(key)\n",
      "File \u001b[1;32m<frozen os>:679\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'OPENAI_API_KEY'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "url = \" https://api.openai.com/v1/chat/completions\"\n",
    "key = os.environ[\"OPENAI_API_KEY\"]\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cannot access local variable 'url' where it is not associated with a value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adski\\OneDrive\\Документы\\Project\\testing.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mindex:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     string \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdf[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m][ind]\u001b[39m}\u001b[39;00m\u001b[39m, type: \u001b[39m\u001b[39m{\u001b[39;00mdf[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m][ind]\u001b[39m}\u001b[39;00m\u001b[39m, info: \u001b[39m\u001b[39m{\u001b[39;00mdf[\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m][ind]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     embedding_from_string(string)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(embedding_cache))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(embedding_cache_path, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m embedding_cache_file:\n",
      "\u001b[1;32mc:\\Users\\adski\\OneDrive\\Документы\\Project\\testing.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     newEmbedding \u001b[39m=\u001b[39m OpenAiClass(body)\u001b[39m.\u001b[39mcall_openAi()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mprint\u001b[39m(newEmbedding)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     newEmbedding \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(newEmbedding)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     embedding_cache[(string, model)] \u001b[39m=\u001b[39m newEmbedding[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/adski/OneDrive/%D0%94%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Project/testing.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mreturn\u001b[39;00m embedding_cache[(string, model)]\n",
      "File \u001b[1;32mc:\\Users\\adski\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(s, (\u001b[39mbytes\u001b[39m, \u001b[39mbytearray\u001b[39m)):\n\u001b[1;32m--> 339\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    340\u001b[0m                         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n",
      "\u001b[1;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not NoneType"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from ChatGPT import OpenAiClass\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "# import of the api key\n",
    "env_path = Path('ChatGPT/.env')\n",
    "\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "from openai.embeddings_utils import (\n",
    "    get_embedding,\n",
    "    distances_from_embeddings,\n",
    "    tsne_components_from_embeddings,\n",
    "    chart_from_components,\n",
    "    indices_of_nearest_neighbors_from_distances,\n",
    ")\n",
    "\n",
    "# constants\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# take product data csv table\n",
    "dataset_path = \"productData.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# establish a cache of embeddings to avoid recomputing\n",
    "# cache is a dict of tuples (text, model) -> embedding, saved as a pickle file\n",
    "\n",
    "# set path to embedding cache\n",
    "embedding_cache_path = \"recommendations_embeddings_cache.pkl\"\n",
    "\n",
    "# load the cache if it exists, and save a copy to disk\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "# with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "#     pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "\n",
    "# define a function to retrieve embeddings from the cache if present, and otherwise request via the API\n",
    "def embedding_from_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    embedding_cache=embedding_cache\n",
    ") -> list:\n",
    "    \"\"\"Return embedding of given string, using a cache to avoid recomputing.\"\"\"\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        body = {\"input\": string,\n",
    "            \"model\": model}\n",
    "        newEmbedding = OpenAiClass(body).call_openAi(\"emeddings\")\n",
    "        print(newEmbedding)\n",
    "        newEmbedding = json.loads(newEmbedding)\n",
    "        embedding_cache[(string, model)] = newEmbedding[\"data\"][0][\"embedding\"]\n",
    "    return embedding_cache[(string, model)]\n",
    "\n",
    "# iterate through all articles -> generate embeddings\n",
    "for ind in df.index:\n",
    "    string = f\"{df['title'][ind]}, type: {df['type'][ind]}, info: {df['body'][ind]}\"\n",
    "    embedding_from_string(string)\n",
    "print(len(embedding_cache))\n",
    "with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "    pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "def print_recommendations_from_strings(\n",
    "    query_string: str,\n",
    "    index_of_source_string: int,\n",
    "    k_nearest_neighbors: int = 1,\n",
    "    model=EMBEDDING_MODEL,\n",
    ") -> list[int]:\n",
    "    \"\"\"Print out the k nearest neighbors of a given string.\"\"\"\n",
    "\n",
    "    #get embedding for the query string\n",
    "    body = {\"input\": query_string,\n",
    "    \"model\": model}\n",
    "    query_embedding = OpenAiClass(body).call_openAi(action=\"embeddings\")\n",
    "    query_embedding = json.loads(query_embedding)\n",
    "    query_embedding = query_embedding[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    # get embeddings for all strings\n",
    "    embeddings = pd.read_pickle(embedding_cache_path)\n",
    "\n",
    "    # get the embedding of the source string\n",
    "    for key in embeddings:\n",
    "        comparison_embedding = embeddings[key]\n",
    "\n",
    "\n",
    "    # get distances between the source embedding and other embeddings (function from embeddings_utils.py)\n",
    "    distances = distances_from_embeddings(query_embedding, embeddings, distance_metric=\"cosine\")\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)\n",
    "\n",
    "    # # # print out source string\n",
    "    # # query_string = strings[index_of_source_string]\n",
    "    # print(f\"Source string: {query_string}\")\n",
    "    # # print out its k nearest neighbors\n",
    "    # k_counter = 0\n",
    "    # for i in indices_of_nearest_neighbors:\n",
    "    #     # stop after printing out k articles\n",
    "    #     if k_counter >= k_nearest_neighbors:\n",
    "    #         break\n",
    "    #     k_counter += 1\n",
    "\n",
    "    # #     # print out the similar strings and their distances\n",
    "    #     print(\n",
    "    #         f\"\"\"\n",
    "    #     --- Recommendation #{k_counter} (nearest neighbor {k_counter} of {k_nearest_neighbors}) ---\n",
    "    #     String: {query_string}\n",
    "    #     Distance: {distances[i]:0.3f}\"\"\"\n",
    "    #     )\n",
    "\n",
    "    # return indices_of_nearest_neighbors\n",
    "# print_recommendations_from_strings(\"3M-Medica Micropore Pflaster\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --- Recommendation #1 (nearest neighbor 1 of 5) ---\n",
      "        String: ('3M-Medica Micropore Pflaster, hautfarben - 12 Stück, type: Pflaster, info: <h2>3M-Medica Micropore Pflaster, hautfarben - 12 Stück</h2>\\n<p><strong>Micropore Pflaster für die Wundauflagenbefestigung</strong></p>\\n<p><strong>Details</strong></p>\\n<p>Das 3M-Medical Micropore Pflaster ist die Nummer 1 der hypoallergenen \"Papier\"-Tapes für die Wundauflagenbefestigung.</p>\\n<ul>\\n<li>hypoallergenes Pflaster</li>\\n<li>2,50 cm x 9,1 m</li>\\n<li>hautfarbe</li>\\n<li>12 Stück pro Packung</li>\\n</ul>', 'text-embedding-ada-002')\n",
      "        Distance: 0.055\n",
      "\n",
      "        --- Recommendation #2 (nearest neighbor 2 of 5) ---\n",
      "        String: ('3M Tegaderm CHG Chlorhexidingluconat I.V. Fixierverband - 7 x 8,5 cm, type: Fixierverband, info: <h2>3M Tegaderm CHG Chlorhexidingluconat I.V. Fixierverband - 7 x 8,5 cm</h2>\\n<h5><strong>wasserfester, steriler Schutz vor externen Verunreinigungen wie Flüssigkeiten, Bakterien und Viren etc.</strong></h5>\\n<p><strong>Details</strong></p>\\n<p>3M Tegaderm™ CHG Chlorhexidingluconat I.V. Fixierverband ist ein antimikrobieller und transparenter Verband mit integriertem CHG-Gelkissen. Nachweisliche Reduktion von katheter-assoziierten Blutstrominfektionen und Katheterbesiedelung – kombiniert die antimikrobielle Aktivität mit der hohen Leistung eines Tegaderm-Verbands.</p>\\n<ul class=\"MMM--pdpList SNAPS--bullets\">\\n<li>Integrierter I.V.-Verband gewährleistet Reduzierung von Infektionen sowie Sichtbarkeit der Einstichstelle, Katheterfixierung und Atmungsaktivität</li>\\n<li>Nachgewiesene Reduktion von katheter-assoziierten Blutstrominfektionen und Katheterbesiedelung</li>\\n<li>Bietet dank des integrierten CHG-(Chlorhexidingluconat-)Gelkissens sofortigen und anhaltenden antimikrobiellen Schutz, ohne dass Feuchtigkeit für die Aktivierung erforderlich wäre</li>\\n<li>Auf die Minimierung von Katheterbewegungen und -dislokation ausgelegt. Hält Katheter mithilfe eines großen Fixierstreifens und einer sich anpassenden Schlüssellochkerbe an Ort und Stelle.</li>\\n<li>Der transparente Film und das Gelkissen ermöglichen eine fortlaufende Sichtbarkeit der Einstichstelle, um frühe Anzeichen einer Infektion leicht zu erkennen</li>\\n<li>Der atmungsaktive Verband lässt Feuchtigkeit von der Haut verdunsten</li>\\n<li>Das integrierte Design (antimikrobielles Gelkissen und Verband in einem) ermöglicht eine einfache und konsistente Applikation</li>\\n<li>Kann bis zu sieben Tage getragen werden</li>\\n<li>Für einen wasserfesten, sterilen Schutz vor externen Verunreinigungen wie Flüssigkeiten, Bakterien und Viren.*</li>\\n<li>Ein Applikationsrahmen ermöglicht eine exakte und problemlose Applikation, was die Gefahr des Klebenbleibens an Handschuhen oder am Material selbst reduziert.</li>\\n<li>7 x 8,5 cm</li>\\n<li>25 Stück pro Packung</li>\\n</ul>\\n<p><strong>Anwendungsbereich</strong></p>\\n<ul class=\"MMM--pdpList SNAPS--bullets\">\\n<li>Zentrale Venenkatheter (einschließlich Subclavia-, Jugularis-, Femoralis- und PICC-Line-Katheter)</li>\\n<li>Dialysekatheter</li>\\n<li>Arterielle Katheter</li>\\n<li>Kurze periphere I.V.-Katheter und Midline-Venenkatheter</li>\\n<li>Epiduralkatheter</li>\\n<li>Sonstige perkutane Vorrichtungen</li>\\n</ul>', 'text-embedding-ada-002')\n",
      "        Distance: 0.170\n",
      "\n",
      "        --- Recommendation #3 (nearest neighbor 3 of 5) ---\n",
      "        String: ('3M Atemschutzmaske Aura 9332+ FFP3 NR D mit Ausatemventil - 1 Stück, type: FFP3 Maske, info: <h2>3M Atemschutzmaske Aura 9332+ FFP3 mit Ausatemventil - 1 Stück</h2>\\n<p><strong>FFP3 Atemschutzmaske zum Schutz vor jeglichen Partikeln</strong></p>\\n<p><strong>Details</strong></p>\\n<p>Die 3M Atemschutzmaske Aura 9332+ FFP3 NR D mit Ausatemventil schützt Sie vor gesundheitsschädliche und krebserzeugende Partikel auf Wasser- und Ölbasis. Die Höchste der drei FFP-Klassen hat eine maximale Gesamtleckage (Undichtigkeit) von 2% und filtert mindestens 99% der Schadstoffe aus der Luft. Die FFP3 Maske bietet somit einen effektiven Atemschutz in der industriellen Anwendung, wenn die Arbeiter Stäuben und/oder nicht flüchtigen Flüssigkeiten ausgesetzt sind</p>\\n<ul>\\n<li>Geprüft und CE-zertifiziert nach EN 149:2001 + A1:2009</li>\\n<li>CE2797</li>\\n<li>Faltbar, einfache Lagerung, 3-teiliges Design passt sich komfortabel den Gesichtsbewegungen an</li>\\n<li>Neue Filtertechnologie für effektive Filterleistung bei niedrigem Atemwiderstand</li>\\n<li>Die spezielle Gestaltung der Nasenregion passt sich optimal der Gesichtsform an und verbessert die Kompatibilität mit Brillen und Augenschutz</li>\\n<li>Die innovative Kinnlasche erleichtert das Aufsetzen und das richtige Positionieren im Gesicht</li>\\n<li>Das 3M™ Cool Flow™ Ausatemventil ist besonders angenehm in heißer Umgebung und/oder bei schwerer Arbeit</li>\\n<li>Angenehmes Tragegefühl auf der Haut durch die große, weiche Polsterung im Nasenbereich</li>\\n<li>Hygienische Einzelverpackung verhindert Verschmutzung der Maske vor ihrem Einsatz</li>\\n<li>Siegelpunkte reduzieren beim Ausatmen den Luftfluss durch die Maskenoberseite und so das Beschlagen von Brillen</li>\\n<li>Der gleichmäßiger Druck der Kopfbänder erhöht den Komfort im Gesicht, im Nacken und am Kopf bei einem sicheren Gefühl.</li>\\n<li>MHD: 12/25</li>\\n<li>1 Stück pro Packung</li>\\n</ul>\\n<p><strong>Weitere Informationen entnehmen Sie bitte den Datenblättern.</strong></p>', 'text-embedding-ada-002')\n",
      "        Distance: 0.179\n",
      "\n",
      "        --- Recommendation #4 (nearest neighbor 4 of 5) ---\n",
      "        String: ('Ambu BlueSensor Elektrode Millipore - 50 Stück, type: Elektrode, info: <h2>Ambu BlueSensor Elektrode Millipore - 50 Stück</h2>\\n<p><strong>Markenqualität mit hervorragenden Ableitungsergebnissen</strong></p>\\n<p><strong>Details</strong></p>\\n<ul>\\n<li>Typ: Erwachsene, SP-00-S</li>\\n<li>Sensor: Silber/Silberchlorid</li>\\n<li>vorgeliert</li>\\n<li>mit Millipore-Schaumstoffring und Druckknopfanschluß</li>\\n<li>Markenqualität mit hervorragenden Ableitungsergebnissen</li>\\n<li>ø 38 mm</li>\\n<li>50 Stück pro Packung</li>\\n</ul>', 'text-embedding-ada-002')\n",
      "        Distance: 0.188\n",
      "\n",
      "        --- Recommendation #5 (nearest neighbor 5 of 5) ---\n",
      "        String: ('Air Queen partikelfiltrierender Mund-Nasen-Schutz CE2163, type: FFP2 Maske, info: <h3>Air Queen Medizinischer Mund-Nasen-Schutz CE2163</h3>\\n<p><b>Mund-Nasen-Schutz Premium CE2163</b></p>\\n<p><strong>Details</strong></p>\\n<p> </p>\\n<p>Air Queen Breeze Mask CE2163<br>\\nEN 149:2001+A1:2009<br>\\nFarbe: weiß</p>\\n<p> </p>\\n<p>– Verpackt in 1er – 10er Bündel – 600 pro Überkarton</p>\\n<p> </p>\\n<p>·  Atemschutzmaske mit CE-Kennzeichnung<br>\\n·  erfüllt den Prüfstandard EN149:2001+A1:2009 der Schutzklasse 2<br>\\n·  feiner Nano-Faser-Filter mit hoher Filterleistung<br>\\n·  Extrem leichtes Gewicht (nur 4,38 g)<br>\\n·  bestens für Brillenträger/innen geeignet, vermindert das Beschlagen<br>\\n·  hoher Tragekomfort, liegt perfekt am Gesicht an<br>\\n·  hygienische, staubsichere Einzelverpackung<br>\\n·  Atemschutzmaske gefaltet mit CE-Kennzeichnung<br>\\n·  bietet sowohl Fremd- als auch Eigenschutz<br>\\n·  die ergonomische Passform mit einstellbarem Nasenbügel und Ohrschlaufen<br>\\n·  alternativ durch beiliegendem Clip mit Kopfschlaufe gewähren hohen Tragekomfort den ganzen Tag<br>\\n·  Latexfrei</p>\\n<p> </p>\\n<p><b>Air QUEEN - unsere neue Atemschutzmaske der Schutzklasse 2</b></p>\\n<p>Bester Tragekomfort</p>\\n<p>·  Atemschutzmaske gefaltet mit CE-Kennzeichnung<br>\\n·  erfüllt den Prüfstandard EN149:2001-A1:2009 der Schutzklasse 2<br>\\n(PSA = persönliche Schutzausrüstung)<br>\\n·  feiner Nanofaser-Filter mit hoher Filterleistung<br>\\n·  bietet sowohl Fremd- als auch Eigenschutz<br>\\n·  hygienische, staubsichere Einzelverpackung<br>\\n·  extrem leichtes Gewicht (nur 4,38 g)<br>\\n·  hoher Tragekomfort, liegt perfekt am Gesicht an<br>\\n·  bestens für Brillenträger/innen geeignet, vermindert das Beschlagen<br>\\n·  die ergonomische Passform mit einstellbarem Nasenbügel und Ohrschlaufen oder alternativ durch beiliegendem Clip mit Kopfschlaufe gewähren hohen Tragekomfort den ganzen Tag<br>\\n·  Latexfrei</p>\\n<p> </p>\\n<p><b>Nanofaser-Technologie:</b><br>\\nMit einer Dicke von einem milliardstel Meter ist das Nano-Material sterisch in einer Fischnetz-Matrix angeordnet, um optimale Filtration, Haltbarkeit und Atmungsaktivität zu gewährleisten.</p>\\n<p> </p>\\n<p><b>Nanofaser-Filter:</b><br>\\nDer Nanofaser-Filter (Mikrofasermembran, 3-lagig) der Air QUEEN Breeze Mask filtert alle Partikel, die größer als 0,1 µm sind. „Coronaviren selbst haben einen Durchmesser von 0,12–0,16 μm, werden aber in der Regel als Bestandteil größerer Partikel<br>\\nausgeschieden”. (Quelle: Umweltbundesamt)</p>\\n<p> </p>\\n<p><b>Einzelverpackung:</b><br>\\ngarantiert hygienisch, staubsicher, lange Haltbarkeit</p>\\n<p> </p>\\n<p>Bitte beachten Sie:</p>\\n<p>Auch die beste Maske ersetzt nicht das Einhalten von Mindestabständen sowie regelmäßiges gründliches Händewaschen. Auch sollten Sie sich trotz Maske nicht in das Gesicht fassen.</p>\\n<p>Bitte halten Sie sich an die Vorgaben der Bundes- und Staatsregierung. Wir möchten, dass Sie andere und sich schützen können!</p>\\n<p>Hygieneartikel sind vom Umtausch ausgeschlossen.</p>', 'text-embedding-ada-002')\n",
      "        Distance: 0.191\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from ChatGPT import OpenAiClass\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "# import of the api key\n",
    "env_path = Path('ChatGPT/.env')\n",
    "\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "from openai.embeddings_utils import (\n",
    "    get_embedding,\n",
    "    distances_from_embeddings,\n",
    "    tsne_components_from_embeddings,\n",
    "    chart_from_components,\n",
    "    indices_of_nearest_neighbors_from_distances,\n",
    ")\n",
    "\n",
    "# constants\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# take product data csv table\n",
    "dataset_path = \"productData.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# establish a cache of embeddings to avoid recomputing\n",
    "# cache is a dict of tuples (text, model) -> embedding, saved as a pickle file\n",
    "\n",
    "# set path to embedding cache\n",
    "embedding_cache_path = \"recommendations_embeddings_cache.pkl\"\n",
    "\n",
    "# load the cache if it exists, and save a copy to disk\n",
    "try:\n",
    "    embedding_cache = pd.read_pickle(embedding_cache_path)\n",
    "except FileNotFoundError:\n",
    "    embedding_cache = {}\n",
    "# with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "#     pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "\n",
    "# define a function to retrieve embeddings from the cache if present, and otherwise request via the API\n",
    "def embedding_from_string(\n",
    "    string: str,\n",
    "    model: str = EMBEDDING_MODEL,\n",
    "    embedding_cache=embedding_cache\n",
    ") -> list:\n",
    "    \"\"\"Return embedding of given string, using a cache to avoid recomputing.\"\"\"\n",
    "    if (string, model) not in embedding_cache.keys():\n",
    "        body = {\"input\": string,\n",
    "            \"model\": model}\n",
    "        newEmbedding = OpenAiClass(body).call_openAi(action=\"embeddings\")\n",
    "        newEmbedding = json.loads(newEmbedding)\n",
    "        embedding_cache[(string, model)] = newEmbedding[\"data\"][0][\"embedding\"]\n",
    "    return embedding_cache[(string, model)]\n",
    "\n",
    "# iterate through all articles -> generate embeddings\n",
    "# for ind in df.index:\n",
    "#     string = f\"{df['title'][ind]}, type: {df['type'][ind]}, info: {df['body'][ind]}\"\n",
    "#     embedding_from_string(string)\n",
    "# print(len(embedding_cache))\n",
    "# with open(embedding_cache_path, \"wb\") as embedding_cache_file:\n",
    "#     pickle.dump(embedding_cache, embedding_cache_file)\n",
    "\n",
    "def print_recommendations_from_strings(\n",
    "    query_string: str,\n",
    "    index_of_source_string: int,\n",
    "    k_nearest_neighbors: int = 5,\n",
    "    model=EMBEDDING_MODEL,\n",
    ") -> list[int]:\n",
    "    \"\"\"Print out the k nearest neighbors of a given string.\"\"\"\n",
    "\n",
    "    #get embedding for the query string\n",
    "    body = {\"input\": query_string,\n",
    "    \"model\": model}\n",
    "    query_embedding = OpenAiClass(body).call_openAi(action=\"embeddings\")\n",
    "    query_embedding = json.loads(query_embedding)\n",
    "    query_embedding = query_embedding[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    # get embeddings for all strings\n",
    "    embeddingsDict = pd.read_pickle(embedding_cache_path)\n",
    "\n",
    "    # get the embedding of the source string\n",
    "    embeddingsList = list(embeddingsDict.values())\n",
    "\n",
    "    # get distances between the source embedding and other embeddings (function from embeddings_utils.py)\n",
    "    distances = distances_from_embeddings(query_embedding, embeddingsList, distance_metric=\"cosine\")\n",
    "    # get indices of nearest neighbors (function from embeddings_utils.py)\n",
    "    indices_of_nearest_neighbors = indices_of_nearest_neighbors_from_distances(distances)\n",
    "\n",
    "    # print out its k nearest neighbors\n",
    "    k_counter = 0\n",
    "    for i in indices_of_nearest_neighbors:\n",
    "        # stop after printing out k articles\n",
    "        if k_counter >= k_nearest_neighbors:\n",
    "            break\n",
    "        k_counter += 1\n",
    "        \n",
    "        for key,val in embeddingsDict.items():\n",
    "            if val == embeddingsList[i]:\n",
    "                embeddingString = key\n",
    "    #     # print out the similar strings and their distances\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        --- Recommendation #{k_counter} (nearest neighbor {k_counter} of {k_nearest_neighbors}) ---\n",
    "        String: {embeddingString}\n",
    "        Distance: {distances[i]:0.3f}\"\"\"\n",
    "        )\n",
    "\n",
    "    # return indices_of_nearest_neighbors\n",
    "print_recommendations_from_strings(\"3M-Medica Micropore Pflaster\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is ready\n",
      "0.26208487770332123 AMPri Med-Comfort Bunte Nitrilhandschuhe\n",
      "0.2716385452720004 AMPri Solid Safety Clean Protect Industriehandschuh - Größe XL\n",
      "0.28514699721317477 AMPri Pura Comfort blue Nitrilhandschuhe, blau\n",
      "0.3098360250167268 AMPri Nature Gloves Nitrilhandschuhe Biologisch abbaubar, puderfrei\n",
      "0.3151397537711575 AMPri Montage- und Arbeitshandschuhe SolidSafety Tough\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "# constants\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "DATASET_PATH = \"productData.csv\"\n",
    "EMBEDDING_CASH_PATH = \"recommendations_embeddings_cache.pkl\"\n",
    "\n",
    "# import of the api key\n",
    "env_path = Path('ChatGPT/.env')\n",
    "\n",
    "\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "embeddingsDict = pd.read_pickle(EMBEDDING_CASH_PATH)\n",
    "\n",
    "\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "chroma_client = chromadb.PersistentClient()\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "    print (\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print (\"OPENAI_API_KEY environment variable not found\")\n",
    "\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(api_key=os.environ.get('OPENAI_API_KEY'), model_name=EMBEDDING_MODEL)\n",
    "\n",
    "\n",
    "# products_collection = chroma_client.delete_collection (name='products_collection')\n",
    "products_collection = chroma_client.get_or_create_collection(name='products_collection', embedding_function=embedding_function )\n",
    "\n",
    "# ids = []\n",
    "# for i in range(50):\n",
    "#     ids.append(f\"{i}\")\n",
    "\n",
    "# strings = []\n",
    "# for ind in df.index:\n",
    "#     strings.append(f\"{df['title'][ind]}, type: {df['type'][ind]}, info: {df['body'][ind]}\")\n",
    "\n",
    "# products_collection.add(\n",
    "#     documents=strings,\n",
    "#     ids=ids\n",
    "# )\n",
    "results = products_collection.query(query_texts=\"Nitril handschuhe grösse M\", n_results=5, include=['distances'])\n",
    "titles = [df[\"title\"][ind] for ind in [int(i) for i in results['ids'][0]]]\n",
    "for i,title in zip(results[\"distances\"][0], titles):\n",
    "        print(i, title)\n",
    "# def query_collection(collection, query, max_results, dataframe):\n",
    "#     results = collection.query(query_texts=query, n_results=max_results, include=['distances'])\n",
    "#     titles = []\n",
    "#     indexes = [int(i) for i in results['ids'][0]]\n",
    "#     titles = [dataframe[\"title\"][ind] for ind in [int(i) for i in results['ids'][0]]]\n",
    "#     df = pd.DataFrame({\n",
    "#                 'id':results['ids'][0], \n",
    "#                 'score':results['distances'][0],\n",
    "#                 \"title\": [dataframe[\"title\"][ind] for ind in [int(i) for i in results['ids'][0]]]\n",
    "#                 })\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# query_collection(products_collection, \"Rapid Schnelltest\", 5, df)\n",
    "# results = products_collection.query(query_texts=\"3M-Medica Micropore Pflaster\", n_results=5)\n",
    "# results[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When choosing gloves, it's important to consider the specific purpose and intended use\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# import of the api key\n",
    "env_path = Path('ChatGPT/.env')\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant on a web site of a e-commerce company, which sells health related products\"},\n",
    "    {\"role\": \"user\", \"content\": \"What material of gloves should i choose?\"},\n",
    "  ],\n",
    "  max_tokens=15\n",
    ")\n",
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
